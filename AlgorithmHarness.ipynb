{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a179382-ef6f-4c12-b2ac-1df2d1366791",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dd2323-41a8-4128-a36e-e785aa99abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lazypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e510a05a-143e-4eac-9b1d-c516a5f05426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde4150a-082b-4314-9480-9d1ca661ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "X, y = shuffle(boston.data, boston.target, random_state=13)\n",
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fea66e-6b30-4223-a6c9-f9c0abbff5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = int(X.shape[0] * 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b033cc-0d36-4283-8e9c-ef2baeab4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:offset], y[:offset]\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f67cc-aeab-41ed-aff0-10db49e308e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc42fc3-22d8-479b-a528-c2971b20a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d315ef-d80c-4c33-9112-267e1544e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/fenago/introml/main/Life%20Expectancy%20Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7137cf-11ad-47fb-8913-ec25775cd61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbfc5ec-8246-4eaf-9ae8-9a08c75b58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c77fc5-ecfc-439f-b486-0ba4336d6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a2014-4954-480b-a28f-4659084575b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Cleaning\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_') # A\n",
    " \n",
    "string_columns = list(df.dtypes[df.dtypes == 'object'].index) # B\n",
    " \n",
    "for col in string_columns:\n",
    "    df[col] = df[col].str.lower().str.replace(' ', '_') # C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fada0f-7220-40c5-a15e-2810e63f4217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into test, train, validation sets... 80/20\n",
    "from sklearn.model_selection import train_test_split\n",
    "# This gives the 80/20 train test split\n",
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=11)\n",
    "\n",
    "len(df_train_full), len(df_test)\n",
    "# Replace nulls with 0's - these are pandas dataframes\n",
    "df_train_full = df_train_full.fillna(0)\n",
    "\n",
    "df_test = df_test.fillna(0)\n",
    "len(df_train_full),len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af400a26-1b03-496e-8c4a-f8bd989e1f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the y out into train/test/splits... these are numpy ndarrays ... msrp is your target variables\n",
    "# Replace with your target variable!!!  \n",
    "y_train = (df_train_full.life_expectancy_).values\n",
    "y_test = (df_test.life_expectancy_).values\n",
    "del df_train_full['life_expectancy_']\n",
    "del df_test['life_expectancy_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b72f08-e861-4895-96d0-86b5b78d7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert these data frames into a LIST of DICTIONARIES (each element in the list is a dictionary (the record))\n",
    "dict_train = df_train_full.to_dict(orient='records')\n",
    "dict_test = df_test.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e4f1b-68b9-4c43-8289-aed92bc5c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the LIST OF DICTIONARIES into a Feature Matrix (does all of the encoding)\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    " \n",
    "dv = DictVectorizer(sparse=False)\n",
    " \n",
    "X_train = dv.fit_transform(dict_train)\n",
    "X_test = dv.transform(dict_test)\n",
    "# features = dv.get_feature_names_out()  #Features as they exist in the Vectorized Dictionary (this is an ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206bc730-1971-4320-9477-321d76273eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f91a2-44db-4e44-bd5e-62bc709e0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c890b5-808d-4959-a58f-95cf1c136006",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f4a365-ad16-4c3c-b64c-b0d5e7ecedbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y= data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.5,random_state =123)\n",
    "\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feaf765-ca0a-4aa8-9e5c-ee5d5c10e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/fenago/classify/main/data/online_shoppers_intention.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb9b68-e767-47fd-8ea1-8bbdde9a5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27dccb-cdca-4405-baa0-1a8c3691c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Cleaning\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_') # A\n",
    " \n",
    "string_columns = list(df.dtypes[df.dtypes == 'object'].index) # B\n",
    " \n",
    "for col in string_columns:\n",
    "    df[col] = df[col].str.lower().str.replace(' ', '_') # C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5867c7-ab08-43e2-a90d-151afded50b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into test, train, validation sets... 80/20\n",
    "from sklearn.model_selection import train_test_split\n",
    "# This gives the 80/20 train test split\n",
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=11)\n",
    "\n",
    "len(df_train_full), len(df_test)\n",
    "# Replace nulls with 0's - these are pandas dataframes\n",
    "df_train_full = df_train_full.fillna(0)\n",
    "\n",
    "df_test = df_test.fillna(0)\n",
    "len(df_train_full),len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e45808-8c14-40f1-a09a-de540e12c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the y out into train/test/splits... these are numpy ndarrays ... msrp is your target variables\n",
    "# Replace with your target variable!!!  \n",
    "y_train = (df_train_full.revenue).values\n",
    "y_test = (df_test.revenue).values\n",
    "del df_train_full['revenue']\n",
    "del df_test['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4881ada-a1df-4cb0-abc4-f579fd81e870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert these data frames into a LIST of DICTIONARIES (each element in the list is a dictionary (the record))\n",
    "dict_train = df_train_full.to_dict(orient='records')\n",
    "dict_test = df_test.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20f82be-7e01-4345-8d5d-0e82ea70cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the LIST OF DICTIONARIES into a Feature Matrix (does all of the encoding)\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    " \n",
    "dv = DictVectorizer(sparse=False)\n",
    " \n",
    "X_train = dv.fit_transform(dict_train)\n",
    "X_test = dv.transform(dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1779136d-15a7-4963-be83-6b28896f51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd607349-ce6a-44d8-ac8d-9fc4ea71b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1191e9-46de-4495-9de0-fdcf0a8c032a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
